import os
import sys
import time
import shutil
from datetime import datetime
from typing import Optional
from enum import IntEnum

import config
from src.feishu_client import FeishuClient
from src.converter import MarkdownToFeishu, FeishuToMarkdown

class SyncResult(IntEnum):
    SUCCESS = 0
    EMPTY_CLOUD = 1
    ERROR = 2

class SyncManager:
    """
    Handles synchronization of a single Markdown file with a Feishu Document.
    """
    def __init__(self, md_path: str, doc_token: str, force: bool = False):
        self.md_path = md_path
        self.doc_token = doc_token
        self.force = force
        self.client = FeishuClient(
            config.FEISHU_APP_ID, 
            config.FEISHU_APP_SECRET
        )
        
    def run(self):
        """
        Main execution flow for file synchronization.
        """
        if not os.path.exists(self.md_path):
            print(f"âŒ é”™è¯¯: æœªæ‰¾åˆ°æ–‡ä»¶: {self.md_path}")
            sys.exit(1)
            
        print(f"ğŸ“– æ­£åœ¨è¯»å–æœ¬åœ°æ–‡ä»¶: {self.md_path}...")
        local_mtime = os.path.getmtime(self.md_path)
        print(f"ğŸ•’ æœ¬åœ°æ–‡ä»¶ä¿®æ”¹æ—¶é—´: {datetime.fromtimestamp(local_mtime)}")
        
        # Check cloud status
        print(f"ğŸ” æ­£åœ¨æ£€æŸ¥äº‘ç«¯æ–‡æ¡£çŠ¶æ€ ({self.doc_token})...")
        file_info = self.client.get_file_info(self.doc_token)
        
        should_upload = True
        
        if not file_info:
            print("âŒ é”™è¯¯: æ— æ³•è·å–äº‘ç«¯æ–‡æ¡£å…ƒæ•°æ®ã€‚")
            if not self.force:
                print("ğŸš« æ“ä½œç»ˆæ­¢ã€‚è¯·ä½¿ç”¨ --force å‚æ•°å¼ºåˆ¶ç»§ç»­ã€‚")
                sys.exit(1)
        else:
            cloud_mtime = self._parse_cloud_time(file_info.latest_modify_time)
            print(f"â˜ï¸ äº‘ç«¯æ–‡æ¡£ä¿®æ”¹æ—¶é—´: {datetime.fromtimestamp(cloud_mtime)}")
            
            if cloud_mtime > local_mtime:
                print("\nâš ï¸ è­¦å‘Š: äº‘ç«¯ç‰ˆæœ¬ æ¯” æœ¬åœ°ç‰ˆæœ¬ æ–°ï¼")
                if self.force:
                    print("ğŸ’ª å·²å¯ç”¨ --force å‚æ•°ï¼Œå°†å¼ºåˆ¶è¦†ç›–ã€‚")
                    should_upload = True
                else:
                    print("ğŸ”„ å¼€å§‹åå‘åŒæ­¥ (äº‘ç«¯ -> æœ¬åœ°)...")
                    result = self._sync_cloud_to_local()
                    if result == SyncResult.SUCCESS:
                        print("âœ… åå‘åŒæ­¥å®Œæˆã€‚")
                        should_upload = False
                    elif result == SyncResult.EMPTY_CLOUD:
                        print("â„¹ï¸ äº‘ç«¯æ–‡æ¡£ä¸ºç©ºï¼Œå‡†å¤‡ä¸Šä¼ æœ¬åœ°å†…å®¹ã€‚")
                        should_upload = True
                    else:
                        print("âŒ åå‘åŒæ­¥å¤±è´¥ï¼Œæ“ä½œç»ˆæ­¢ã€‚")
                        sys.exit(1)
            else:
                print("âœ… æœ¬åœ°ç‰ˆæœ¬è¾ƒæ–°æˆ–ä¸€è‡´ï¼Œå‡†å¤‡åŒæ­¥åˆ°äº‘ç«¯ã€‚")
                should_upload = True

        if should_upload:
            self._sync_local_to_cloud()

    def _parse_cloud_time(self, timestamp) -> float:
        """
        Heuristic to detect if timestamp is in milliseconds or seconds.
        """
        ts = int(timestamp)
        if ts > 10000000000:
            return ts / 1000.0
        return float(ts)

    def _sync_cloud_to_local(self) -> SyncResult:
        """
        Downloads cloud content and overwrites local file.
        Returns SyncResult enum.
        """
        print(f"ğŸ“¥ æ­£åœ¨ä¸‹è½½äº‘ç«¯å†…å®¹å¹¶è¦†ç›–æœ¬åœ°æ–‡ä»¶: {self.md_path}...")
        
        try:
            blocks = self.client.get_all_blocks(self.doc_token)
            if not blocks:
                print("âš ï¸ è­¦å‘Š: äº‘ç«¯æ–‡æ¡£ä¸ºç©ºï¼Œæ— éœ€ä¸‹è½½ã€‚")
                return SyncResult.EMPTY_CLOUD
            
            # Define image downloader callback
            def image_downloader(token: str) -> Optional[str]:
                # Assets folder: ./assets
                assets_dir = os.path.join(os.path.dirname(self.md_path), "assets")
                filename = f"{token}.png" # Default to png
                save_path = os.path.join(assets_dir, filename)
                
                if self.client.download_image(token, save_path):
                    # Return relative path for markdown
                    return os.path.join("assets", filename)
                return None

            converter = FeishuToMarkdown(image_downloader=image_downloader)
            md_content = converter.convert(blocks)
            
            # Backup
            backup_path = f"{self.md_path}.bak.{int(time.time())}"
            shutil.copy2(self.md_path, backup_path)
            print(f"ğŸ“¦ å·²åˆ›å»ºæœ¬åœ°å¤‡ä»½: {backup_path}")
            
            with open(self.md_path, "w", encoding="utf-8") as f:
                f.write(md_content)
                
            print(f"âœ… æˆåŠŸä½¿ç”¨äº‘ç«¯å†…å®¹è¦†ç›–æœ¬åœ°æ–‡ä»¶ã€‚")
            return SyncResult.SUCCESS
            
        except Exception as e:
            print(f"âŒ åå‘åŒæ­¥è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return SyncResult.ERROR

    def _sync_local_to_cloud(self):
        """
        Reads local file, converts to blocks, and uploads to Feishu.
        """
        print("ğŸ”„ æ­£åœ¨å°† Markdown è½¬æ¢ä¸ºé£ä¹¦æ–‡æ¡£å—...")
        with open(self.md_path, "r", encoding="utf-8") as f:
            md_text = f.read()
            
        # Define image uploader callback
        def image_uploader(src: str) -> Optional[str]:
            # Resolve path
            # If src is absolute, use it. If relative, join with md_path dir.
            if os.path.isabs(src):
                abs_path = src
            else:
                abs_path = os.path.join(os.path.dirname(self.md_path), src)
            
            if os.path.exists(abs_path):
                return abs_path
            
            print(f"âŒ å›¾ç‰‡æœªæ‰¾åˆ°: {abs_path}")
            return None

        converter = MarkdownToFeishu(image_uploader=image_uploader)
        blocks = converter.parse(md_text)
        print(f"âœ¨ å·²ç”Ÿæˆ {len(blocks)} ä¸ªæ–‡æ¡£å—ã€‚")
        
        print(f"ğŸ§¹ æ­£åœ¨æ¸…ç©ºäº‘ç«¯æ–‡æ¡£åŸå§‹å†…å®¹ ({self.doc_token})...")
        self.client.clear_document(self.doc_token)
        
        print("ğŸ“¤ æ­£åœ¨ä¸Šä¼ æ–°å†…å®¹...")
        self.client.add_blocks(self.doc_token, blocks)
        
        doc_url = f"https://feishu.cn/docx/{self.doc_token}"
        print(f"âœ… åŒæ­¥å®Œæˆï¼æ–‡æ¡£é“¾æ¥: {doc_url}")


class FolderSyncManager:
    """
    Handles recursive synchronization of a local folder with a Feishu Cloud Folder.
    """
    def __init__(self, local_root: str, cloud_root_token: str, force: bool = False):
        self.local_root = local_root
        self.cloud_root_token = cloud_root_token
        self.force = force
        self.client = FeishuClient(
            config.FEISHU_APP_ID, 
            config.FEISHU_APP_SECRET
        )
        
        # Stats
        self.total_files = 0
        self.processed_files = 0

        if self.cloud_root_token == "root":
            print("ğŸ” æ­£åœ¨è§£ææ ¹ç›®å½•(æˆ‘çš„ç©ºé—´) Token...")
            root_token = self.client.get_root_folder_token()
            if root_token:
                print(f"âœ… å·²è§£ææ ¹ç›®å½• Token: {root_token}")
                self.cloud_root_token = root_token
            else:
                print("âŒ é”™è¯¯: æ— æ³•è§£ææ ¹ç›®å½• Tokenã€‚")
                sys.exit(1)

    def run(self):
        """
        Main execution flow for folder synchronization.
        """
        if not os.path.exists(self.local_root):
            print(f"âŒ é”™è¯¯: æœªæ‰¾åˆ°æœ¬åœ°æ–‡ä»¶å¤¹: {self.local_root}")
            sys.exit(1)
        
        print(f"ğŸ“Š æ­£åœ¨ç»Ÿè®¡æ–‡ä»¶æ•°é‡...")
        self.total_files = self._count_files(self.local_root)
        print(f"ğŸ“¦ å‘ç° {self.total_files} ä¸ª Markdown æ–‡ä»¶ã€‚")

        print(f"ğŸš€ å¼€å§‹æ–‡ä»¶å¤¹åŒæ­¥: {self.local_root} -> {self.cloud_root_token}")
        self._sync_folder(self.local_root, self.cloud_root_token)
        print("\n" + "="*50)
        print(f"ğŸ‰ æ–‡ä»¶å¤¹åŒæ­¥å®Œæˆã€‚å…±å¤„ç† {self.processed_files}/{self.total_files} ä¸ªæ–‡ä»¶ã€‚")

    def _count_files(self, path: str) -> int:
        count = 0
        for root, dirs, files in os.walk(path):
            # Skip hidden folders
            dirs[:] = [d for d in dirs if not d.startswith('.')]
            for file in files:
                if file.endswith(".md") and not file.startswith('.'):
                    count += 1
        return count

    def _sync_folder(self, local_path: str, cloud_token: str):
        """
        Recursively syncs files and subfolders.
        """
        # 1. List cloud files in this folder
        # Only print scanning log if it's the root or we want verbose logs
        # print(f"ğŸ” æ­£åœ¨æ‰«æäº‘ç«¯æ–‡ä»¶å¤¹: {cloud_token}...")
        cloud_files = self.client.list_folder_files(cloud_token)
        # Map: name -> (token, type)
        cloud_map = {f.name: f for f in cloud_files}

        # 2. Iterate local files
        items = sorted(os.listdir(local_path))
        for item in items:
            if item.startswith('.'): continue # Skip hidden
            
            item_path = os.path.join(local_path, item)
            
            if os.path.isdir(item_path):
                # Handle Folder
                if item in cloud_map:
                    # Check if it is a folder
                    if cloud_map[item].type == "folder":
                        # print(f"ğŸ“‚ è¿›å…¥å­æ–‡ä»¶å¤¹: {item}")
                        self._sync_folder(item_path, cloud_map[item].token)
                    else:
                        print(f"âš ï¸ è­¦å‘Š: åç§°å†²çªã€‚æœ¬åœ°æ˜¯æ–‡ä»¶å¤¹ï¼Œä½†äº‘ç«¯æ˜¯ {cloud_map[item].type}ã€‚è·³è¿‡: {item}ã€‚")
                else:
                    # Create folder
                    print(f"ğŸ“ æ­£åœ¨åˆ›å»ºäº‘ç«¯æ–‡ä»¶å¤¹: {item}")
                    new_token = self.client.create_folder(cloud_token, item)
                    if new_token:
                        self._sync_folder(item_path, new_token)
            
            elif item.endswith(".md"):
                self.processed_files += 1
                doc_name = item[:-3] # Remove .md
                
                print(f"\n" + "-"*50)
                print(f"ğŸ“„ [{self.processed_files}/{self.total_files}] å¤„ç†æ–‡ä»¶: {item}")
                print("-" * 50)
                
                if doc_name in cloud_map:
                    # Sync
                    c_file = cloud_map[doc_name]
                    if c_file.type == "docx":
                        sync = SyncManager(item_path, c_file.token, self.force)
                        sync.run()
                    else:
                        print(f"âš ï¸ è­¦å‘Š: åç§°å†²çªã€‚æœ¬åœ°æ˜¯ .md æ–‡ä»¶ï¼Œä½†äº‘ç«¯æ˜¯ {c_file.type}ã€‚è·³è¿‡ã€‚")
                else:
                    # Create Doc
                    print(f"ğŸ“ æ­£åœ¨åˆ›å»ºäº‘ç«¯æ–‡æ¡£: {doc_name}")
                    new_token = self.client.create_docx(cloud_token, doc_name)
                    if new_token:
                        print(f"âœ¨ å·²åˆ›å»ºæ–‡æ¡£ {doc_name} ({new_token}), å¼€å§‹åŒæ­¥å†…å®¹...")
                        # Newly created doc needs force upload to bypass timestamp check
                        sync = SyncManager(item_path, new_token, force=True)
                        sync.run()
