import os
import sys
import time
import shutil
from datetime import datetime
from typing import Optional
from enum import IntEnum
from urllib.parse import unquote
import difflib

import config
from src.feishu_client import FeishuClient
from src.converter import MarkdownToFeishu, FeishuToMarkdown
from src.utils import calculate_block_hash, pad_center, parse_cloud_time

class SyncResult(IntEnum):
    SUCCESS = 0
    EMPTY_CLOUD = 1
    ERROR = 2

class SyncManager:
    """
    Handles synchronization of a single Markdown file with a Feishu Document.
    """
    # Cache for vault asset index: { vault_root: { filename: full_path } }
    _asset_index_cache = {}

    def __init__(self, md_path: str, doc_token: str, force: bool = False, vault_root: str = None):
        self.md_path = md_path
        self.doc_token = doc_token
        self.force = force
        self.vault_root = vault_root or os.path.dirname(md_path)
        self.client = FeishuClient(
            config.FEISHU_APP_ID, 
            config.FEISHU_APP_SECRET,
            user_access_token=config.FEISHU_USER_ACCESS_TOKEN
        )

    def _get_asset_path_from_index(self, filename: str) -> Optional[str]:
        """
        Look up file path in the vault-wide asset index.
        """
        if not self.vault_root:
            return None
            
        # Initialize cache if needed
        if self.vault_root not in SyncManager._asset_index_cache:
            print(f"ğŸ” æ­£åœ¨å»ºç«‹ Vault èµ„æºç´¢å¼• (é¦–æ¬¡è¿è¡Œ): {self.vault_root} ...")
            asset_map = {}
            for root, dirs, files in os.walk(self.vault_root):
                # Skip hidden folders
                dirs[:] = [d for d in dirs if not d.startswith('.')]
                for f in files:
                    if f.startswith('.'): continue
                    # Index media and typical attachments
                    if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp', '.svg', 
                                         '.pdf', '.mp4', '.mov', '.avi', '.mkv', '.zip', '.docx', '.xlsx', '.pptx')):
                        asset_map[f] = os.path.join(root, f)
            
            print(f"ğŸ“š ç´¢å¼•å®Œæˆï¼Œå…± {len(asset_map)} ä¸ªèµ„æºæ–‡ä»¶ã€‚")
            SyncManager._asset_index_cache[self.vault_root] = asset_map
            
        return SyncManager._asset_index_cache[self.vault_root].get(filename)
        
    def run(self):
        """
        Main execution flow for file synchronization.
        """
        print(f"\n{'-'*30}")
        print(f"ğŸ“„ ä»»åŠ¡: {os.path.basename(self.md_path)}")
        print(f"{'-'*30}")

        if not os.path.exists(self.md_path):
            print(f"âŒ é”™è¯¯: æœªæ‰¾åˆ°æ–‡ä»¶: {self.md_path}")
            sys.exit(1)
            
        print(f"ğŸ“– è¯»å–æœ¬åœ°æ–‡ä»¶: {self.md_path}...")
        local_mtime = os.path.getmtime(self.md_path)
        print(f"ğŸ•’ æœ¬åœ°æ–‡ä»¶ä¿®æ”¹æ—¶é—´: {datetime.fromtimestamp(local_mtime)}")
        
        # Check cloud status
        print(f"ğŸ” æ­£åœ¨æ£€æŸ¥äº‘ç«¯æ–‡æ¡£çŠ¶æ€ ({self.doc_token})...")
        file_info = self.client.get_file_info(self.doc_token)
        
        should_upload = True
        
        if not file_info:
            print("âŒ é”™è¯¯: æ— æ³•è·å–äº‘ç«¯æ–‡æ¡£å…ƒæ•°æ®ã€‚")
            if not self.force:
                print("ğŸš« æ“ä½œç»ˆæ­¢ã€‚è¯·ä½¿ç”¨ --force å‚æ•°å¼ºåˆ¶ç»§ç»­ã€‚")
                sys.exit(1)
        else:
            cloud_mtime = parse_cloud_time(file_info.latest_modify_time)
            print(f"â˜ï¸ äº‘ç«¯æ–‡æ¡£ä¿®æ”¹æ—¶é—´: {datetime.fromtimestamp(cloud_mtime)}")
            
            if cloud_mtime > local_mtime:
                print("\nâš ï¸ è­¦å‘Š: äº‘ç«¯ç‰ˆæœ¬ æ¯” æœ¬åœ°ç‰ˆæœ¬ æ–°ï¼")
                if self.force:
                    print("ğŸ’ª å·²å¯ç”¨ --force å‚æ•°ï¼Œå°†å¼ºåˆ¶è¦†ç›–ã€‚")
                    should_upload = True
                else:
                    print("ğŸ”„ å¼€å§‹åå‘åŒæ­¥ (äº‘ç«¯ -> æœ¬åœ°)...")
                    result = self._sync_cloud_to_local()
                    if result == SyncResult.SUCCESS:
                        print("âœ… åå‘åŒæ­¥å®Œæˆã€‚")
                        should_upload = False
                    elif result == SyncResult.EMPTY_CLOUD:
                        print("â„¹ï¸ äº‘ç«¯æ–‡æ¡£ä¸ºç©ºï¼Œå‡†å¤‡ä¸Šä¼ æœ¬åœ°å†…å®¹ã€‚")
                        should_upload = True
                    else:
                        print("âŒ åå‘åŒæ­¥å¤±è´¥ï¼Œæ“ä½œç»ˆæ­¢ã€‚")
                        sys.exit(1)
            else:
                print("âœ… æœ¬åœ°ç‰ˆæœ¬è¾ƒæ–°æˆ–ä¸€è‡´ï¼Œå‡†å¤‡åŒæ­¥åˆ°äº‘ç«¯ã€‚")
                should_upload = True

        if should_upload:
            self._sync_local_to_cloud()

    def _sync_cloud_to_local(self) -> SyncResult:
        """
        Downloads cloud content and overwrites local file.
        Returns SyncResult enum.
        """
        print(f"ğŸ“¥ æ­£åœ¨ä¸‹è½½äº‘ç«¯å†…å®¹å¹¶è¦†ç›–æœ¬åœ°æ–‡ä»¶: {self.md_path}...")
        
        try:
            blocks = self.client.get_all_blocks(self.doc_token)
            if not blocks:
                print("âš ï¸ è­¦å‘Š: äº‘ç«¯æ–‡æ¡£ä¸ºç©ºï¼Œæ— éœ€ä¸‹è½½ã€‚")
                return SyncResult.EMPTY_CLOUD
            
            # Define image downloader callback
            def image_downloader(token: str) -> Optional[str]:
                # Assets folder: ./assets
                assets_dir = os.path.join(os.path.dirname(self.md_path), "assets")
                if not os.path.exists(assets_dir):
                    os.makedirs(assets_dir)
                    
                filename = f"{token}.png" # Default to png
                save_path = os.path.join(assets_dir, filename)
                
                if self.client.download_image(token, save_path):
                    # Return relative path for markdown
                    return os.path.join("assets", filename)
                return None

            converter = FeishuToMarkdown(image_downloader=image_downloader)
            md_content = converter.convert(blocks)
            
            # Backup
            backup_path = f"{self.md_path}.bak.{int(time.time())}"
            shutil.copy2(self.md_path, backup_path)
            print(f"ğŸ“¦ å·²åˆ›å»ºæœ¬åœ°å¤‡ä»½: {backup_path}")
            
            with open(self.md_path, "w", encoding="utf-8") as f:
                f.write(md_content)
                
            print(f"âœ… æˆåŠŸä½¿ç”¨äº‘ç«¯å†…å®¹è¦†ç›–æœ¬åœ°æ–‡ä»¶ã€‚")
            return SyncResult.SUCCESS
            
        except Exception as e:
            print(f"âŒ åå‘åŒæ­¥è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return SyncResult.ERROR

    def _sync_local_to_cloud(self):
        """
        Reads local file, converts to blocks, and uploads to Feishu.
        Implements incremental sync (Diff) strategy.
        """
        print("ğŸ”„ æ­£åœ¨å°† Markdown è½¬æ¢ä¸ºé£ä¹¦æ–‡æ¡£å—...")
        with open(self.md_path, "r", encoding="utf-8") as f:
            md_text = f.read()
            
        # Define image uploader callback
        def image_uploader(src: str) -> Optional[str]:
            # Decode URL encoded chars (e.g. %20 -> space)
            src = unquote(src)

            # Resolve path strategies
            
            # 1. Check if it's already an absolute path and exists
            if os.path.isabs(src) and os.path.exists(src):
                return src
                
            # 2. Check relative to MD file (Standard Markdown)
            path_rel_md = os.path.join(os.path.dirname(self.md_path), src)
            if os.path.exists(path_rel_md):
                return path_rel_md
            
            # 3. Check relative to Vault Root (Obsidian Style)
            if self.vault_root:
                path_rel_vault = os.path.join(self.vault_root, src)
                if os.path.exists(path_rel_vault):
                    return path_rel_vault
                
                # 4. Check in 'assets' folder in Vault Root (Common convention)
                path_assets = os.path.join(self.vault_root, "assets", os.path.basename(src))
                if os.path.exists(path_assets):
                    return path_assets

            # 5. Last Resort: Vault-wide search (Obsidian fuzzy link)
            filename = os.path.basename(src)
            path_from_index = self._get_asset_path_from_index(filename)
            if path_from_index and os.path.exists(path_from_index):
                 return path_from_index
            
            print(f"âŒ å›¾ç‰‡æœªæ‰¾åˆ°: {src}")
            return None

        converter = MarkdownToFeishu(image_uploader=image_uploader)
        local_blocks = converter.parse(md_text)
        print(f"âœ¨ æœ¬åœ°å·²ç”Ÿæˆ {len(local_blocks)} ä¸ªæ–‡æ¡£å—ã€‚")
        
        # --- Incremental Sync Logic ---
        
        # 1. Fetch Cloud Blocks
        print(f"ğŸ” è·å–äº‘ç«¯ç°æœ‰å†…å®¹ä»¥è¿›è¡Œæ¯”å¯¹...")
        cloud_blocks_raw = self.client.get_all_blocks(self.doc_token)
        
        # 2. Compute Hashes
        cloud_hashes = [calculate_block_hash(b, is_cloud_obj=True) for b in cloud_blocks_raw]
        local_hashes = [calculate_block_hash(b, is_cloud_obj=False) for b in local_blocks]
        
        # 3. Calculate Diff
        sm = difflib.SequenceMatcher(None, cloud_hashes, local_hashes)
        opcodes = sm.get_opcodes()
        
        ops_count = 0
        for tag, i1, i2, j1, j2 in opcodes:
            if tag != 'equal':
                ops_count += 1
        
        if ops_count == 0:
            print("âœ… æ–‡æ¡£å†…å®¹ä¸€è‡´ï¼Œæ— éœ€æ›´æ–°ã€‚")
            return

        print(f"ğŸ“Š å·®å¼‚åˆ†æ: å‘ç° {ops_count} å¤„å˜æ›´ã€‚")
        
        if ops_count > 10 or len(cloud_blocks_raw) == 0:
            print("âš ï¸ å˜æ›´è¾ƒå¤šæˆ–ä¸ºç©ºæ–‡æ¡£ï¼Œä½¿ç”¨å…¨é‡è¦†ç›–æ¨¡å¼ä»¥ç¡®ä¿é€Ÿåº¦...")
            self.client.clear_document(self.doc_token)
            self.client.add_blocks(self.doc_token, local_blocks)
        else:
            print("âš¡ï¸ ä½¿ç”¨å¢é‡åŒæ­¥æ¨¡å¼...")
            
            # Table Header
            w_type = 8
            w_cloud = 12
            w_local = 12
            
            print(f"  â”Œ{'â”€'*w_type}â”¬{'â”€'*w_cloud}â”¬{'â”€'*w_local}â”")
            print(f"  â”‚{pad_center('ç±»å‹', w_type)}â”‚{pad_center('äº‘ç«¯å—ç´¢å¼•', w_cloud)}â”‚{pad_center('æœ¬åœ°å—ç´¢å¼•', w_local)}â”‚")
            print(f"  â”œ{'â”€'*w_type}â”¼{'â”€'*w_cloud}â”¼{'â”€'*w_local}â”¤")
            
            # Collect operations to execute
            ops_to_exec = []
            
            for tag, i1, i2, j1, j2 in reversed(opcodes):
                if tag == 'equal':
                    continue
                
                # Print readable diff
                action_map = {'delete': 'ğŸ”´ åˆ é™¤', 'insert': 'ğŸŸ¢ æ’å…¥', 'replace': 'ğŸŸ¡ æ›¿æ¢'}
                icon = action_map.get(tag, tag)
                
                c_range = f"{i1:02d}-{i2:02d}"
                l_range = f"{j1:02d}-{j2:02d}"
                
                print(f"  â”‚{pad_center(icon, w_type)}â”‚{pad_center(c_range, w_cloud)}â”‚{pad_center(l_range, w_local)}â”‚")
                
                ops_to_exec.append((tag, i1, i2, j1, j2))
            
            print(f"  â””{'â”€'*w_type}â”´{'â”€'*w_cloud}â”´{'â”€'*w_local}â”˜")
            
            print("ğŸš€ å¼€å§‹æ‰§è¡ŒåŒæ­¥æ“ä½œ...")
            for tag, i1, i2, j1, j2 in ops_to_exec: # Order is already reversed
                if tag == 'delete':
                    self.client.delete_blocks_by_index(self.doc_token, i1, i2)
                elif tag == 'insert':
                    blocks_to_insert = local_blocks[j1:j2]
                    self.client.add_blocks(self.doc_token, blocks_to_insert, index=i1)
                elif tag == 'replace':
                    self.client.delete_blocks_by_index(self.doc_token, i1, i2)
                    blocks_to_insert = local_blocks[j1:j2]
                    self.client.add_blocks(self.doc_token, blocks_to_insert, index=i1)

        doc_url = f"https://feishu.cn/docx/{self.doc_token}"
        print(f"âœ… åŒæ­¥å®Œæˆï¼æ–‡æ¡£é“¾æ¥: {doc_url}")


class FolderSyncManager:
    """
    Handles recursive synchronization of a local folder with a Feishu Cloud Folder.
    """
    def __init__(self, local_root: str, cloud_root_token: str, force: bool = False, vault_root: str = None):
        self.local_root = local_root
        self.cloud_root_token = cloud_root_token
        self.force = force
        self.vault_root = vault_root or local_root
        self.client = FeishuClient(
            config.FEISHU_APP_ID, 
            config.FEISHU_APP_SECRET,
            user_access_token=config.FEISHU_USER_ACCESS_TOKEN
        )
        
        # Stats
        self.total_files = 0
        self.processed_files = 0

        if self.cloud_root_token == "root":
            print("ğŸ” æ­£åœ¨è§£ææ ¹ç›®å½•(æˆ‘çš„ç©ºé—´) Token...")
            root_token = self.client.get_root_folder_token()
            if root_token:
                print(f"âœ… å·²è§£ææ ¹ç›®å½• Token: {root_token}")
                self.cloud_root_token = root_token
            else:
                print("âŒ é”™è¯¯: æ— æ³•è§£ææ ¹ç›®å½• Tokenã€‚")
                sys.exit(1)

    def run(self):
        """
        Main execution flow for folder synchronization.
        """
        if not os.path.exists(self.local_root):
            print(f"âŒ é”™è¯¯: æœªæ‰¾åˆ°æœ¬åœ°æ–‡ä»¶å¤¹: {self.local_root}")
            sys.exit(1)
        
        print(f"ğŸ“Š æ­£åœ¨ç»Ÿè®¡æ–‡ä»¶æ•°é‡...")
        self.total_files = self._count_files(self.local_root)
        print(f"ğŸ“¦ å‘ç° {self.total_files} ä¸ª Markdown æ–‡ä»¶ã€‚")

        print(f"ğŸš€ å¼€å§‹æ–‡ä»¶å¤¹åŒæ­¥: {self.local_root} -> {self.cloud_root_token}")
        self._sync_folder(self.local_root, self.cloud_root_token)
        print("\n" + "="*50)
        print(f"ğŸ‰ æ–‡ä»¶å¤¹åŒæ­¥å®Œæˆã€‚å…±å¤„ç† {self.processed_files}/{self.total_files} ä¸ªæ–‡ä»¶ã€‚")

    def _count_files(self, path: str) -> int:
        count = 0
        for root, dirs, files in os.walk(path):
            # Skip hidden folders
            dirs[:] = [d for d in dirs if not d.startswith('.')]
            for file in files:
                if file.endswith(".md") and not file.startswith('.'):
                    count += 1
        return count

    def _sync_folder(self, local_path: str, cloud_token: str):
        """
        Recursively syncs files and subfolders.
        """
        cloud_files = self.client.list_folder_files(cloud_token)
        # Map: name -> (token, type)
        cloud_map = {f.name: f for f in cloud_files}

        items = sorted(os.listdir(local_path))
        for item in items:
            if item.startswith('.'): continue # Skip hidden
            
            item_path = os.path.join(local_path, item)
            
            if os.path.isdir(item_path):
                # Handle Folder
                if item in cloud_map:
                    if cloud_map[item].type == "folder":
                        self._sync_folder(item_path, cloud_map[item].token)
                    else:
                        print(f"âš ï¸ è­¦å‘Š: åç§°å†²çªã€‚æœ¬åœ°æ˜¯æ–‡ä»¶å¤¹ï¼Œä½†äº‘ç«¯æ˜¯ {cloud_map[item].type}ã€‚è·³è¿‡: {item}ã€‚")
                else:
                    print(f"ğŸ“ æ­£åœ¨åˆ›å»ºäº‘ç«¯æ–‡ä»¶å¤¹: {item}")
                    new_token = self.client.create_folder(cloud_token, item)
                    if new_token:
                        self._sync_folder(item_path, new_token)
            
            elif item.endswith(".md"):
                self.processed_files += 1
                doc_name = item[:-3] # Remove .md
                
                print(f"\n" + "="*50)
                print(f"ğŸ“‚ [{self.processed_files}/{self.total_files}] å¤„ç†æ–‡ä»¶: {item}")
                print("=" * 50)
                
                if doc_name in cloud_map:
                    # Sync
                    c_file = cloud_map[doc_name]
                    if c_file.type == "docx":
                        sync = SyncManager(item_path, c_file.token, self.force, vault_root=self.vault_root)
                        sync.run()
                    else:
                        print(f"âš ï¸ è­¦å‘Š: åç§°å†²çªã€‚æœ¬åœ°æ˜¯ .md æ–‡ä»¶ï¼Œä½†äº‘ç«¯æ˜¯ {c_file.type}ã€‚è·³è¿‡ã€‚")
                else:
                    # Create Doc
                    print(f"ğŸ“ æ­£åœ¨åˆ›å»ºäº‘ç«¯æ–‡æ¡£: {doc_name}")
                    new_token = self.client.create_docx(cloud_token, doc_name)
                    if new_token:
                        print(f"âœ¨ å·²åˆ›å»ºæ–‡æ¡£ {doc_name} ({new_token}), å¼€å§‹åŒæ­¥å†…å®¹...")
                        
                        # Newly created doc needs force upload to bypass timestamp check
                        sync = SyncManager(item_path, new_token, force=True, vault_root=self.vault_root)
                        sync.run()
